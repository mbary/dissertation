{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'database_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e7857e29e620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# interactive mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatabase_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabasereader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatabaseReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Custom Functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'database_functions'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from database_functions.databasereader import DatabaseReader\n",
    "\n",
    "# Custom Functions\n",
    "from shoe_dataset import ShoeDataSet\n",
    "from shoe_dataset import train_transformations, valid_transformations\n",
    "from feature_maps_extractor import ExtractFeatureMaps\n",
    "from class_activation_maps import ScoreCam\n",
    "\n",
    "torch.manual_seed(1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_model:\n",
    "    \n",
    "    def __init__(self, model_type,unfreeze_layers, freeze_factor = 1 ,pretrained = True, output_dir = \"./runs/\"):\n",
    "        \n",
    "        if torch.cuda.is_available():      \n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "            print(\"Model set up on the GPU\")\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "            print(\"Running on the CPU\")\n",
    "        \n",
    "        \n",
    "        # Define the backbone model\n",
    "        if model_type == \"resnet101\":\n",
    "            self.model = models.resnet101(pretrained=pretrained)\n",
    "        \n",
    "        elif model_type == \"resnet50\":\n",
    "            self.model = models.resnet50(pretrained=pretrained)        \n",
    "        \n",
    "        else: \n",
    "            print(\"model type unrecognised\")\n",
    "            \n",
    "        print(f\"Model backbone set to: {model_type}\")\n",
    "        \n",
    "        # Push the model to device\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.unfreeze_layers = unfreeze_layers\n",
    "        self.freeze_factor = freeze_factor\n",
    "        \n",
    "        if self.freeze_factor == 1:\n",
    "            for name,child in self.model.named_children():\n",
    "                if name not in self.unfreeze_layers:\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False\n",
    "        \n",
    "        else:\n",
    "            for name,child in self.model.named_children():\n",
    "                if name not in self.unfreeze_layers:\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_gra = False\n",
    "                    \n",
    "                elif name in self.unfreeze_layers:    \n",
    "                    for param in list(child.parameters())[int(self.freeze_factor*len(list(child.parameters()))):]:\n",
    "                        param.requires_grad = False\n",
    "\n",
    "                        \n",
    "        # Defines the output dir for the model to be saved\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        self.writer = SummaryWriter(self.output_dir,)\n",
    "            \n",
    "    \n",
    "    def train(self, loss_func, optimizer, lr_scheduler,learning_rate, epochs, trainloader, valloader, eval_period = 100 ):\n",
    "\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eval_period = eval_period\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        \n",
    "        # Params of the 4th layer to confirm later \n",
    "        # that layers are correctly frozen\n",
    "        self._original_weight = list(self.model.layer4.parameters())[0]\n",
    "        \n",
    "        \n",
    "        print(f\"Eval Period set to: {self.eval_period}\")\n",
    "\n",
    "        self.criterion = loss_func()\n",
    "        self.optimizer = optimizer(filter(lambda p: p.requires_grad, self.model.parameters()),lr = self.learning_rate)\n",
    "        self.lr_scheduler = lr_scheduler(self.optimizer)\n",
    "\n",
    "        train_epoch_loss = []\n",
    "        train_epoch_acc  = []\n",
    "\n",
    "        val_epoch_loss = []\n",
    "        val_epoch_acc = []\n",
    "\n",
    "        best_val_acc = 0.0\n",
    "        running_training_loss = 0.0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            # check for first 3 epochs whether the layers\n",
    "            # are actually frozen and the weights do not change\n",
    "            \n",
    "            if 0 < epoch < 3:\n",
    "                \n",
    "                print(f\"Did the Weights change in epoch: {epoch}?\")\n",
    "                if list(self.model.layer4.parameters())[0].cpu().numpy().all() == self._original_weight[0].cpu().numpy().all():\n",
    "                    print(\"No\")\n",
    "                else:\n",
    "                    print(\"Yes, abort!!!\")\n",
    "            \n",
    "            \n",
    "\n",
    "            train_batch_loss = []\n",
    "            train_batch_acc = []\n",
    "\n",
    "            val_batch_loss = []\n",
    "            val_batch_acc = []\n",
    "\n",
    "            # train loop\n",
    "            for idx, data in enumerate(self.trainloader):\n",
    "\n",
    "                self.model.train()\n",
    "\n",
    "                inputs,labels = data[\"image\"],data[\"label\"]\n",
    "\n",
    "                # Place tensors on GPU\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Zero out the accumulated gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs,labels.float())\n",
    "                \n",
    "                running_training_loss+=loss.item()\n",
    "\n",
    "                #append the mean train loss (woking on a batch)\n",
    "                #use item() to detach from GPU\n",
    "                train_batch_loss.append(loss.item())\n",
    "\n",
    "                # Identify Correct predictions\n",
    "                correct_preds = [torch.argmax(i)==torch.argmax(j) for i,j in zip(outputs,labels)]\n",
    "                train_acc = correct_preds.count(True)/len(correct_preds)\n",
    "                train_batch_acc.append(train_acc)\n",
    "\n",
    "\n",
    "                # Backwards pass\n",
    "                loss.backward()\n",
    "\n",
    "\n",
    "                self.optimizer.step()                                                                \n",
    "                \n",
    "                # print out stats every N iterations\n",
    "                if idx%500 == 0:\n",
    "                    \n",
    "                    current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                    print(f\"Current lr: {current_lr}\")\n",
    "                    print(f\"Step: {idx}/{len(trainloader)}; Epoch: {epoch+1}/{self.epochs}; Train Batch Loss: {loss.item()}\")\n",
    "            \n",
    "            \n",
    "            self.writer.add_scalar(\"Training Loss\", running_training_loss/len(self.trainloader), epoch)\n",
    "            running_training_loss = 0.0\n",
    "            \n",
    "            train_epoch_loss.append(torch.tensor(train_batch_loss).mean())\n",
    "            train_epoch_acc.append(torch.tensor(train_batch_acc).mean())\n",
    "\n",
    "            running_val_loss = 0\n",
    "            print(\"epoch\",epoch)\n",
    "            print(\"epoch%eval_per\", epoch%self.eval_period)\n",
    "            # Validation loop every self.eval_period epochs\n",
    "            eval_count = 0\n",
    "            if epoch%self.eval_period == 0:\n",
    "                print(f\"Starting evaluating at epoch: {epoch}\")\n",
    "                with torch.no_grad():\n",
    "                    for idx,data in enumerate(self.valloader):\n",
    "\n",
    "                        # set model in eval() mode\n",
    "                        self.model.eval()\n",
    "\n",
    "                        inputs,labels, self.val_file_name = data[\"image\"], data[\"label\"], data[\"file_name\"]\n",
    "                        # Place inputs/lables on the GPU\n",
    "                        inputs = inputs.to(self.device)\n",
    "                        labels = labels.to(self.device)\n",
    "\n",
    "                        # Predict outputs\n",
    "                        outputs = self.model(inputs)\n",
    "\n",
    "                        # Obtain and append val_batch_loss\n",
    "                        val_loss = self.criterion(outputs,labels)\n",
    "                        val_batch_loss.append(loss.item())\n",
    "                        running_val_loss += val_loss\n",
    "\n",
    "                        # Obtain and append val_batch_acc\n",
    "                        correct_preds = [torch.argmax(i) == torch.argmax(j) for i,j in zip(outputs,labels)]\n",
    "\n",
    "                        val_acc = correct_preds.count(True)/len(correct_preds)\n",
    "                        val_batch_acc.append(val_acc)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        if eval_count%3 == 0:\n",
    "                            \n",
    "                            all_feature_maps = []\n",
    "                            \n",
    "                            for name in data[\"file_name\"][:2]:\n",
    "                                all_feature_maps.append(ExtractFeatureMaps(self.model, name))\n",
    "                                \n",
    "                            all_feature_maps_stacked = np.vstack(all_feature_maps)\n",
    "                            self.writer.add_image(\"Feature Maps of every 10th conv layer\", all_feature_maps_stacked,global_step=epoch)\n",
    "                                \n",
    "                            \n",
    "                            all_layers_maps = []\n",
    "                            \n",
    "                            for i in range(1,5):\n",
    "                                score_cam = ScoreCam(self.model, f\"layer{i}\")\n",
    "\n",
    "                                eval_count+=1\n",
    "\n",
    "                                top_images = []\n",
    "                                bottom_images = []\n",
    "\n",
    "                                images = data[\"image\"]\n",
    "                                names = data[\"file_name\"]\n",
    "\n",
    "                                for idx, (image,name) in enumerate(zip(images,names),1):\n",
    "\n",
    "                                    no_trans, heatmap_image = score_cam.generate_cam(input_image=image, filename=name)\n",
    "                                    \n",
    "                                    if idx <= int(len(data)):\n",
    "                                        top_images.append(np.array(heatmap_image))\n",
    "                                        \n",
    "                                    else:\n",
    "                                        bottom_images.append(np.array(heatmap_image))\n",
    "                                        \n",
    "                                top_images = np.hstack(top_images)\n",
    "                                bottom_images = np.hstack(bottom_images)\n",
    "                                all_images = np.vstack((top_images,bottom_images))\n",
    "                                \n",
    "                                all_layers_maps.append(all_images)\n",
    "                            \n",
    "                            all_layers_maps = np.vstack(all_layers_maps)\n",
    "                            \n",
    "                            self.writer.add_image(\"Class Activation Maps, Layers 1-4\", all_layers_maps, global_step = epoch)\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "                    val_epoch_loss.append(torch.tensor(val_batch_loss).mean())\n",
    "                    val_epoch_acc.append(torch.tensor(val_batch_acc).mean())\n",
    "                    \n",
    "                    \n",
    "                    # Visualise the predictions on the last validation batch\n",
    "                    \n",
    "                    print(f\"len inputs of last batch: {len(inputs)}\")\n",
    "                    \n",
    "                    self.writer.add_scalar(\"Validation Loss\", \n",
    "                                           running_val_loss/len(self.valloader),\n",
    "                                           global_step = epoch\n",
    "                                          )\n",
    "                    \n",
    "                    self.writer.add_figure(\"Predictions vs. GT\",\n",
    "                                           self.plot_classes_preds(inputs, labels),\n",
    "                                           global_step = epoch\n",
    "                                          )\n",
    "                    \n",
    "                    running_val_loss = 0.0\n",
    "                    \n",
    "                    \n",
    "            # Save the model which yielding best acc\n",
    "            if val_acc > best_val_acc:\n",
    "                print(f\"Saving model at epoch: {epoch}\")\n",
    "                best_val_acc = val_acc\n",
    "                self.best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "            # Print out \n",
    "\n",
    "            self.lr_scheduler.step(val_acc)\n",
    "\n",
    "\n",
    "        self.model = self.model.load_state_dict(self.model.state_dict())\n",
    "    \n",
    "    def matplotlib_imshow(self, img, one_channel=False):\n",
    "        if one_channel:\n",
    "            img = img.mean(dim=0)\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.cpu().numpy()\n",
    "        if one_channel:\n",
    "            plt.imshow(npimg, cmap=\"Greys\")\n",
    "        else:\n",
    "            plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "            \n",
    "    def images_to_probs(self, images):\n",
    "        '''\n",
    "        Generates predictions and corresponding probabilities from a trained\n",
    "        network and a list of images\n",
    "        '''\n",
    "        output = self.model(images)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, preds_tensor = torch.max(output, 1)\n",
    "        preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "        return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "    def plot_classes_preds(self, images, labels):\n",
    "        '''\n",
    "        Generates matplotlib Figure using a trained network, along with images\n",
    "        and labels from a batch, that shows the network's top prediction along\n",
    "        with its probability, alongside the actual label, coloring this\n",
    "        information based on whether the prediction was correct or not.\n",
    "        Uses the \"images_to_probs\" function.\n",
    "        '''\n",
    "        preds, probs = self.images_to_probs(images)\n",
    "        # plot the images in the batch, along with predicted and true labels\n",
    "        fig = plt.figure(figsize=(48, 15))\n",
    "        for idx in np.arange(4):\n",
    "            ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "            self.matplotlib_imshow(images[idx], one_channel=False)\n",
    "            ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "                classes[preds[idx]],\n",
    "                probs[idx] * 100.0,\n",
    "                classes[labels[idx]]),\n",
    "                        color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"), fontsize=40)\n",
    "        return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Import all data from the database\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "db_reader = DatabaseReader(\"crepcheque\")\n",
    "\n",
    "get_images_query =\"\"\"\n",
    "\n",
    "                    SELECT\n",
    "                        r.crep_id,\n",
    "                        r.raw_brand_text,\n",
    "                        r.image_id,\n",
    "                        r.image_type,\n",
    "                        r.image_file_path\n",
    "                    FROM raw_creps r\n",
    "                    LEFT JOIN\n",
    "                        images i\n",
    "                        ON r.crep_id = i.crep_id\n",
    "                    WHERE \n",
    "                        r.images IS NOT NULL\n",
    "                        AND r.images_processed IS NOT NULL\n",
    "                        AND i.image_downloaded = true\n",
    "\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "database_df = db_reader.send_query(query=get_images_query, return_as_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Shuffle the dataframe and split into train and validation\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "# shuffled_df = sklearn.utils.shuffle(database_df)\n",
    "\n",
    "# train_df = shuffled_df.iloc[:int(database_df.shape[0]*0.8), :]\n",
    "# val_df = shuffled_df.iloc[int(database_df.shape[0]*0.8):, :]\n",
    "\n",
    "X = database_df.image_file_path\n",
    "y = database_df.raw_brand_text\n",
    "\n",
    "X_train,y_train, X_valid, y_valid = train_test_split(X,y, test_size = 0.2 ,stratify = y, \n",
    "                                                     shuffle = True, random_state = 1994)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train],axis=1)\n",
    "val_df = pd.concat([X_valid,y_valid], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomPerspective(p=0.4)\n",
       "    RandomHorizontalFlip(p=0.2)\n",
       "    Resize(size=(300, 300), interpolation=PIL.Image.BILINEAR)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Define the image transformatoins for the train and validation sets\n",
    "Define \n",
    "\n",
    "\"\"\"\n",
    "train_transforms = train_transformations()\n",
    "valid_transforms = valid_transformations()\n",
    "\n",
    "train_set = ShoeDataSet(train_df, transform=train_transforms)\n",
    "val_set = ShoeDataSet(val_df, transform=valid_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=4)\n",
    "val_loader = DataLoader(val_set, shuffle=True, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Add layers which are to be unfrozen for finetuning purposes\n",
    "\n",
    "Options: fc (bare minimum), layer1-4 (conv2d layer bottlenecks)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "custom_model = custom_model(\"resnet101\",[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Redefine the FC layer of your model so that it matches \n",
    "the number of classes present in the dataset\n",
    "\n",
    "Ensure that it is placed on the GPU - .cuda()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "in_features = custom_model.model.avgpool.out_features\n",
    "\n",
    "custom_model.model.fc = torch.nn.Linear(in_features, len(y)).cuda()\n",
    "\n",
    "# Define the output directory for the logs\n",
    "custom_model.output_dir = \"./logs\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Define the loss functoin (criterion)\n",
    "OPtimizer - Adam\n",
    "LRScheduler\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "criterion = torch.nn.MSELoss\n",
    "optimizer = torch.optim.Adam\n",
    "learning_rate = 0.001\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Initialise the training of the model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# small eval period for debugging purposes\n",
    "\n",
    "model.train(loss_function = criterion, optimizer = optimizer, lr_scheduler = lr_scheduler, \n",
    "           learning_rate = learning_rate, epochs = 10, trainloader = train_loader, \n",
    "           val_loader = val_loader, eval_period = 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
